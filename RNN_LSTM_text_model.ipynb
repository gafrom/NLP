{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "RNN LSTM for text classification\n",
    "=============\n",
    "<span style=\"color: lightsteelblue;\">Deep Learning</span>\n",
    "\n",
    "The goal of this notebook is to train recurrent neural network with LSTM cell for the purpose of text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# import re\n",
    "# import string\n",
    "import tensorflow as tf\n",
    "\n",
    "# from six.moves import range\n",
    "# from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "# custom library\n",
    "from nlp.preparer import Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus label: good,  length: 6666 articles,  av length: 321 words,  max length: 4977 words.\n",
      "Corpus raw article: 3 февраля в большинстве европейских стран закрылось зимнее трансферное окно — период, когда клубы могут заявлять новых футболистов, купленных у других команд. Ценники меняются чуть ли не ежемесячно. Н\n",
      "Corpus data (words): ['num', 'февраля', 'в', 'большинстве', 'европейских', 'стран', 'закрылось', 'зимнее', 'трансферное', 'окно', 'период', ',', 'когда', 'клубы', 'могут', 'заявлять', 'новых', 'футболистов', ',', 'купленных']\n",
      "\n",
      "Corpus label: bad,  length: 7519 articles,  av length: 84 words,  max length: 594 words.\n",
      "Corpus raw article: Неизвестный угрожает взорвать аэропорт Кишинева, если ему не дадут миллион. Неизвестный сообщил о бомбе в аэропорту Международного аэропорта Кишинева и требует миллион рублей, сообщили в пограничной п\n",
      "Corpus data (words): ['неизвестный', 'угрожает', 'взорвать', 'аэропорт', 'кишинева', ',', 'если', 'ему', 'не', 'дадут', 'миллион', '.', 'неизвестный', 'сообщил', 'о', 'бомбе', 'в', 'аэропорту', 'международного', 'аэропорта']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpora_paths = ['./articles/good.articles', './articles/bad.articles'] \n",
    "corpora = []\n",
    "lengths = []\n",
    "\n",
    "for path in corpora_paths:\n",
    "  corpus = Corpus(path)\n",
    "  corpora.append(corpus)\n",
    "  length = [len(article) for article in corpus.articles]\n",
    "  lengths.append(length)\n",
    "\n",
    "  print(f\"Corpus label: {corpus.label}, \",\n",
    "        f\"length: {len(corpus.articles)} articles, \",\n",
    "        f\"av length: {round(corpus.average_length())} words, \",\n",
    "        f\"max length: {max(length)} words.\")\n",
    "  print(f\"Corpus raw article: {corpus.raw[0][:200]}\")\n",
    "  print(f\"Corpus data (words): {corpus.articles[0][:20]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binning articles by their lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bins: 52\n",
      "Now our bins contain these numbers of articles: [{6: 4}, {7: 31}, {8: 85}, {9: 225}, {10: 355}, {11: 525}, {12: 603}, {13: 724}, {14: 711}, {15: 619}, {16: 562}, {17: 536}, {18: 460}, {19: 376}, {20: 300}, {21: 260}, {22: 206}, {23: 166}, {24: 131}, {25: 121}, {26: 98}, {27: 80}, {28: 79}, {29: 42}, {30: 41}, {31: 25}, {32: 31}, {33: 15}, {34: 19}, {35: 14}, {36: 6}, {37: 9}, {38: 13}, {39: 8}, {40: 7}, {41: 2}, {42: 3}, {43: 1}, {44: 4}, {45: 2}, {46: 4}, {48: 2}, {49: 3}, {50: 2}, {51: 1}, {52: 1}, {53: 1}, {57: 1}, {58: 2}, {60: 1}, {82: 1}, {118: 1}]\n",
      "Now each article is padded by 2.5 words in average: ['этим', 'правоохранительные', 'органы', 'ищут', 'отправившего', 'сообщение', '.', 'PAD', 'PAD', 'PAD']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAHwCAYAAAARoMr7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkTTBDoSRJkiRNMEOhJEmSJE2w/wNw4cqvEUYE8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f0f4080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bin_size = 5\n",
    "\n",
    "bins = {}\n",
    "for article in corpora[1].articles:\n",
    "  length = len(article)\n",
    "  key = length // bin_size \n",
    "  if key in bins.keys():\n",
    "    bins[key].append(article)\n",
    "  else:\n",
    "    bins[key] = [article]\n",
    "\n",
    "print(f\"Number of bins: {len(bins)}\")\n",
    "bins_representation = [{ key : len(bins[key]) } for key in sorted(bins.keys())]\n",
    "print(f\"Now our bins contain these numbers of articles: {bins_representation}\")\n",
    "\n",
    "# Padding articles to match bins' lengths\n",
    "for key in bins:\n",
    "  must_be = (key + 1) * bin_size - 1\n",
    "  for article in bins[key]:\n",
    "    length = len(article)\n",
    "    if length < must_be:\n",
    "      how_less = must_be - length\n",
    "      for _ in range(how_less): article.append('PAD')\n",
    "\n",
    "print(f\"Now each article is padded by {bin_size / 2} words in average: {corpus.articles[0][-10:]}\")\n",
    "\n",
    "# visualization\n",
    "plt.figure().set_size_inches(15, 8)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.xlabel('Article length (in words)')\n",
    "plt.ylabel('Number of articles')\n",
    "plt.title('Lengths distribution: Good articles')\n",
    "plt.hist(lengths[0], 200)\n",
    "\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.xlabel('Article length (in words)')\n",
    "plt.ylabel('Number of articles')\n",
    "plt.title('Lengths distribution: Bad articles')\n",
    "plt.hist(lengths[1], 200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top popular words counts: [['UNK', 311795], (',', 191060), ('.', 167323), ('в', 121865), ('num', 70531), ('и', 59437), ('на', 47376), ('с', 26509), ('что', 22411), ('по', 21883), ('не', 20173), ('из', 16359), ('PAD', 15063), (')', 12317), ('(', 12286)]\n",
      "\n",
      "Example word: 23733 => слон\n",
      "<PAD> word: 12 => PAD\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 25000\n",
    "\n",
    "def build_dataset(words):\n",
    "  count = [['UNK', -1]]\n",
    "  count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    if word in dictionary:\n",
    "      index = dictionary[word]\n",
    "    else:\n",
    "      index = 0  # dictionary['UNK']\n",
    "      unk_count = unk_count + 1\n",
    "    data.append(index)\n",
    "  count[0][1] = unk_count\n",
    "  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "  return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "# flatten all words into a single bag\n",
    "all_words = [word for corpus in corpora for words in corpus.articles for word in words]\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(all_words)\n",
    "\n",
    "print(f\"Top popular words counts: {count[:15]}\\n\")\n",
    "print(f\"Example word: {dictionary['слон']} => {reverse_dictionary[dictionary['слон']]}\")\n",
    "print(f\"<PAD> word: {dictionary['PAD']} => {reverse_dictionary[dictionary['PAD']]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate a training batch for the LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "\n",
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, num_unrollings):\n",
    "    self._text = text\n",
    "    self._text_size = len(text)\n",
    "    self._batch_size = batch_size\n",
    "    self._num_unrollings = num_unrollings\n",
    "    segment = self._text_size // batch_size\n",
    "    self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "\n",
    "    self._last_batch = self._next_batch()\n",
    "\n",
    "\n",
    "  def _next_batch(self):\n",
    "    \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
    "    batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\n",
    "    for b in range(self._batch_size):\n",
    "      batch[b, self._text[self._cursor[b]]] = 1.0\n",
    "      self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "    return batch\n",
    "\n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "    the last batch of the previous array, followed by num_unrollings new ones.\n",
    "    \"\"\"\n",
    "    batches = [self._last_batch]\n",
    "    for step in range(self._num_unrollings):\n",
    "      batches.append(self._next_batch())\n",
    "    self._last_batch = batches[-1]\n",
    "    return batches\n",
    "\n",
    "def words(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  words back into its (most likely) word representation.\"\"\"\n",
    "  return [reverse_dictionary[c] for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "  for b in batches:\n",
    "    s = [word for word in words(b)]\n",
    "  return s\n",
    "\n",
    "train_batches = BatchGenerator(train_data, batch_size, num_unrollings)\n",
    "valid_batches = BatchGenerator(valid_data, 1, 1)\n",
    "\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(valid_batches.next()))\n",
    "print(batches2string(valid_batches.next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "  \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "  predictions[predictions < 1e-10] = 1e-10\n",
    "  return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "  \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "  probabilities.\n",
    "  \"\"\"\n",
    "  r = random.uniform(0, 1)\n",
    "  s = 0\n",
    "  for i in range(len(distribution)):\n",
    "    s += distribution[i]\n",
    "    if s >= r:\n",
    "      return i\n",
    "  return len(distribution) - 1\n",
    "\n",
    "def sample(prediction):\n",
    "  \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "  p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
    "  p[0, sample_distribution(prediction[0])] = 1.0\n",
    "  return p\n",
    "\n",
    "def random_distribution():\n",
    "  \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "  b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
    "  return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert a partially known TensorShape to a Tensor: (?, 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   1356\u001b[0m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m--> 102\u001b[0;31m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    411\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0mshape_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    411\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m     \u001b[0mshape_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __int__ returned non-int (type NoneType)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6b5aae652acc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0;31m# Variables saving state across unrollings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0msaved_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m   \u001b[0msaved_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;31m# Classifier weights and biases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, name)\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1360\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m    637\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m           \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_tensor_shape_tensor_conversion_function\u001b[0;34m(s, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    129\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     raise ValueError(\n\u001b[0;32m--> 131\u001b[0;31m         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert a partially known TensorShape to a Tensor: (?, 64)"
     ]
    }
   ],
   "source": [
    "num_nodes = 64\n",
    "num_classes = 2\n",
    "embedding_size = 128 # Dimension of a word vector\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  # Parameters:\n",
    "  # Input gate: input, previous output, and bias.\n",
    "  ix = tf.Variable(tf.truncated_normal([embedding_size, num_nodes], -0.1, 0.1))\n",
    "  im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ib = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Forget gate: input, previous output, and bias.\n",
    "  fx = tf.Variable(tf.truncated_normal([embedding_size, num_nodes], -0.1, 0.1))\n",
    "  fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  fb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Output gate: input, previous output, and bias.\n",
    "  ox = tf.Variable(tf.truncated_normal([embedding_size, num_nodes], -0.1, 0.1))\n",
    "  om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ob = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Memory cell: input, state and bias.                             \n",
    "  cx = tf.Variable(tf.truncated_normal([embedding_size, num_nodes], -0.1, 0.1))\n",
    "  cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  cb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Variables saving state across unrollings.\n",
    "  saved_output = tf.Variable(tf.zeros([None, num_nodes]), trainable=False)\n",
    "  saved_state = tf.Variable(tf.zeros([None, num_nodes]), trainable=False)\n",
    "  # Classifier weights and biases.\n",
    "  w = tf.Variable(tf.truncated_normal([num_nodes, num_classes], -0.1, 0.1))\n",
    "  b = tf.Variable(tf.zeros([num_classes]))\n",
    "  # Embeddings\n",
    "  embeddings = tf.Variable(tf.random_uniform([vocabulary_size, embedding_size], -1.0, 1.0))\n",
    "\n",
    "\n",
    "  # Definition of the cell computation.\n",
    "  def lstm_cell(i, o, state):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "\n",
    "    return output_gate * tf.tanh(state), state\n",
    "\n",
    "  # Input data.\n",
    "  train_inputs = tf.placeholder(tf.float32, shape=[num_unrollings])\n",
    "  train_labels = tf.placeholder(tf.float32, shape=[num_unrollings, num_classes])\n",
    "  lstm_inputs = tf.nn.embedding_lookup(embeddings, train_inputs) # ~ (num_unrollings, embedding_size)\n",
    "\n",
    "  # Unrolled LSTM loop.\n",
    "  lstm_outputs = list()\n",
    "  output = saved_output\n",
    "  state = saved_state\n",
    "  for lstm_input in lstm_inputs:\n",
    "    output, state = lstm_cell(lstm_input, output, state)\n",
    "    lstm_outputs.append(output)\n",
    "\n",
    "  # State saving across unrollings.\n",
    "  with tf.control_dependencies([saved_output.assign(output),\n",
    "                                saved_state.assign(state)]):\n",
    "    # Classifier.\n",
    "    logits = tf.nn.xw_plus_b(tf.concat(lstm_outputs, 0), w, b) # ~ (num_unrollings, num_classes)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "      labels=train_labels,\n",
    "      logits=logits\n",
    "    ))\n",
    "\n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "    10.0, global_step, 5000, 0.1, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "  gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "  optimizer = optimizer.apply_gradients(\n",
    "    zip(gradients, v), global_step=global_step)\n",
    "\n",
    "  # Predictions.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "#   # Sampling and validation eval: batch 1, no unrolling.\n",
    "#   sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n",
    "#   saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "#   saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "#   reset_sample_state = tf.group(\n",
    "#     saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "#     saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "#   sample_output, sample_state = lstm_cell(\n",
    "#     sample_input, saved_sample_output, saved_sample_state)\n",
    "#   with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "#                                 saved_sample_state.assign(sample_state)]):\n",
    "#     sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 7001\n",
    "summary_frequency = 100\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.global_variables_initializer().run()\n",
    "  print('Initialized')\n",
    "  mean_loss = 0\n",
    "  for step in range(num_steps):\n",
    "    batches = train_batches.next()\n",
    "    feed_dict = {}\n",
    "\n",
    "      feed_dict[train_data[i]] = batches[i]\n",
    "    _, l, predictions, lr = session.run(\n",
    "      [optimizer, loss, train_prediction, learning_rate], feed_dict=feed_dict)\n",
    "    mean_loss += l\n",
    "\n",
    "    if step % summary_frequency == 0:\n",
    "      if step > 0:\n",
    "        mean_loss = mean_loss / summary_frequency\n",
    "      # The mean loss is an estimate of the loss over the last few batches.\n",
    "      print(\n",
    "        'Average loss at step %d: %f learning rate: %f' % (step, mean_loss, lr))\n",
    "      mean_loss = 0\n",
    "\n",
    "#       labels = np.concatenate(list(batches)[1:])\n",
    "#       print('Minibatch perplexity: %.2f' % float(\n",
    "#         np.exp(logprob(predictions, labels))))\n",
    "#       if step % (summary_frequency * 10) == 0:\n",
    "#         # Generate some samples.\n",
    "#         print('=' * 80)\n",
    "#         for _ in range(5):\n",
    "#           feed = sample(random_distribution())\n",
    "#           sentence = characters(feed)[0]\n",
    "#           reset_sample_state.run()\n",
    "#           for _ in range(79):\n",
    "#             prediction = sample_prediction.eval({sample_input: feed})\n",
    "#             feed = sample(prediction)\n",
    "#             sentence += characters(feed)[0]\n",
    "#           print(sentence)\n",
    "#         print('=' * 80)\n",
    "#       # Measure validation set perplexity.\n",
    "#       reset_sample_state.run()\n",
    "#       valid_logprob = 0\n",
    "#       for _ in range(valid_size):\n",
    "#         b = valid_batches.next()\n",
    "#         predictions = sample_prediction.eval({sample_input: b[0]})\n",
    "#         valid_logprob = valid_logprob + logprob(predictions, b[1])\n",
    "#       print('Validation set perplexity: %.2f' % float(np.exp(\n",
    "#         valid_logprob / valid_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
