{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN LSTM for text classification\n",
    "=============\n",
    "<span style=\"color: lightsteelblue;\">Deep Learning</span>\n",
    "\n",
    "The goal of this notebook is to train recurrent neural network with LSTM cell for the purpose of text classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "\n",
    "# from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import random\n",
    "# import re\n",
    "# import string\n",
    "import tensorflow as tf\n",
    "\n",
    "# from six.moves import range\n",
    "# from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "# custom library\n",
    "from nlp.preparer import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus label: good,  length: 6666 articles,  av length: 321 words,  max length: 4977 words.\n",
      "Corpus raw article: 3 февраля в большинстве европейских стран закрылось зимнее трансферное окно — период, когда клубы могут заявлять новых футболистов, купленных у других команд. Ценники меняются чуть ли не ежемесячно. На их формирование влияет множество факторов: результативность, желание клубов выгодно заработать, а \n",
      "Corpus data (words): ['number', 'февраля', 'в', 'большинстве', 'европейских', 'стран', 'закрылось', 'зимнее', 'трансферное', 'окно', 'период', ',', 'когда', 'клубы', 'могут', 'заявлять', 'новых', 'футболистов', ',', 'купленных', 'у', 'других', 'команд', '.', 'ценники', 'меняются', 'чуть', 'ли', 'не', 'ежемесячно', '.', 'на', 'их', 'формирование', 'влияет', 'множество', 'факторов', 'результативность', ',', 'желание', 'клубов', 'выгодно', 'заработать', ',', 'а', 'также', 'личные', 'амбиции', 'спортсменов', '.']\n",
      "\n",
      "Corpus label: bad,  length: 7519 articles,  av length: 84 words,  max length: 594 words.\n",
      "Corpus raw article: Неизвестный угрожает взорвать аэропорт Кишинева, если ему не дадут миллион. Неизвестный сообщил о бомбе в аэропорту Международного аэропорта Кишинева и требует миллион рублей, сообщили в пограничной полиции страны. Из -здания эвакуированы пассажиры и персонал, авиарейсы задерживаются.Сотрудники всех\n",
      "Corpus data (words): ['неизвестный', 'угрожает', 'взорвать', 'аэропорт', 'кишинева', ',', 'если', 'ему', 'не', 'дадут', 'миллион', '.', 'неизвестный', 'сообщил', 'о', 'бомбе', 'в', 'аэропорту', 'международного', 'аэропорта', 'кишинева', 'и', 'требует', 'миллион', 'рублей', ',', 'сообщили', 'в', 'пограничной', 'полиции', 'страны', '.', 'из', 'здания', 'эвакуированы', 'пассажиры', 'и', 'персонал', ',', 'авиарейсы', 'задерживаются', '.', 'сотрудники', 'всех', 'подразделений', 'мвд', 'участвуют', 'в', 'операции', 'в']\n",
      "\n",
      "Bin size: 5.94 words\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAE/CAYAAADlpzo+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10eca8898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpora_paths = ['./articles/good.articles', './articles/bad.articles'] \n",
    "corpora = []\n",
    "lengths = []\n",
    "\n",
    "for path in corpora_paths:\n",
    "  corpus = Corpus(path)\n",
    "  corpora.append(corpus)\n",
    "  length = [len(article) for article in corpus.articles]\n",
    "  lengths.append(length)\n",
    "\n",
    "  print(f\"Corpus label: {corpus.label}, \",\n",
    "        f\"length: {len(corpus.articles)} articles, \",\n",
    "        f\"av length: {round(corpus.average_length())} words, \",\n",
    "        f\"max length: {max(length)} words.\")\n",
    "  print(f\"Corpus raw article: {corpus.raw[0][:300]}\")\n",
    "  print(f\"Corpus data (words): {corpus.articles[0][:50]}\\n\")\n",
    "\n",
    "# print([i for i, length in enumerate(lengths[0]) if length == maxes[0]])\n",
    "\n",
    "# binning good articles\n",
    "num_bins = 100\n",
    "bin_size = 594 / num_bins\n",
    "print(f\"Bin size: {bin_size} words\")\n",
    "\n",
    "hist, bin_edges = np.histogram(lengths[0], bins=num_bins)\n",
    "\n",
    "\n",
    "\n",
    "# visualization\n",
    "plt.figure().set_size_inches(15, 5)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title('Lengths distribution: Good articles')\n",
    "plt.bar(range(len(hist)), hist)\n",
    "\n",
    "plt.subplots_adjust(hspace=.5)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title('Lengths distribution: Bad articles')\n",
    "plt.hist(lengths[1], 100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top popular words counts: [['UNK', 311786], (',', 191060), ('.', 167323), ('в', 121865), ('number', 70531), ('и', 59437), ('на', 47376), ('с', 26509), ('что', 22411), ('по', 21883)]\n",
      "Example dictionary item: 23732 => слон\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 25000\n",
    "\n",
    "def build_dataset(words):\n",
    "  count = [['UNK', -1]]\n",
    "  count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "  dictionary = dict()\n",
    "  for word, _ in count:\n",
    "    dictionary[word] = len(dictionary)\n",
    "  data = list()\n",
    "  unk_count = 0\n",
    "  for word in words:\n",
    "    if word in dictionary:\n",
    "      index = dictionary[word]\n",
    "    else:\n",
    "      index = 0  # dictionary['UNK']\n",
    "      unk_count = unk_count + 1\n",
    "    data.append(index)\n",
    "  count[0][1] = unk_count\n",
    "  reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "  return data, count, dictionary, reverse_dictionary\n",
    "\n",
    "# flatten all words into a single bag\n",
    "all_words = [word for corpus in corpora for words in corpus.articles for word in words]\n",
    "\n",
    "data, count, dictionary, reverse_dictionary = build_dataset(all_words)\n",
    "\n",
    "print(f\"Top popular words counts: {count[:10]}\")\n",
    "print(f\"Example dictionary item: {dictionary['слон']} => {reverse_dictionary[23732]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to generate a training batch for the LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "num_unrollings=10\n",
    "\n",
    "class BatchGenerator(object):\n",
    "  def __init__(self, text, batch_size, num_unrollings):\n",
    "    self._text = text\n",
    "    self._text_size = len(text)\n",
    "    self._batch_size = batch_size\n",
    "    self._num_unrollings = num_unrollings\n",
    "    segment = self._text_size // batch_size\n",
    "    self._cursor = [ offset * segment for offset in range(batch_size)]\n",
    "\n",
    "    self._last_batch = self._next_batch()\n",
    "\n",
    "\n",
    "  def _next_batch(self):\n",
    "    \"\"\"Generate a single batch from the current cursor position in the data.\"\"\"\n",
    "    batch = np.zeros(shape=(self._batch_size, vocabulary_size), dtype=np.float)\n",
    "    for b in range(self._batch_size):\n",
    "      batch[b, self._text[self._cursor[b]]] = 1.0\n",
    "      self._cursor[b] = (self._cursor[b] + 1) % self._text_size\n",
    "    return batch\n",
    "\n",
    "  def next(self):\n",
    "    \"\"\"Generate the next array of batches from the data. The array consists of\n",
    "    the last batch of the previous array, followed by num_unrollings new ones.\n",
    "    \"\"\"\n",
    "    batches = [self._last_batch]\n",
    "    for step in range(self._num_unrollings):\n",
    "      batches.append(self._next_batch())\n",
    "    self._last_batch = batches[-1]\n",
    "    return batches\n",
    "\n",
    "def words(probabilities):\n",
    "  \"\"\"Turn a 1-hot encoding or a probability distribution over the possible\n",
    "  words back into its (most likely) word representation.\"\"\"\n",
    "  return [reverse_dictionary[c] for c in np.argmax(probabilities, 1)]\n",
    "\n",
    "def batches2string(batches):\n",
    "  for b in batches:\n",
    "    s = [word for word in words(b)]\n",
    "  return s\n",
    "\n",
    "train_batches = BatchGenerator(train_data, batch_size, num_unrollings)\n",
    "valid_batches = BatchGenerator(valid_data, 1, 1)\n",
    "\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(train_batches.next()))\n",
    "print(batches2string(valid_batches.next()))\n",
    "print(batches2string(valid_batches.next()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logprob(predictions, labels):\n",
    "  \"\"\"Log-probability of the true labels in a predicted batch.\"\"\"\n",
    "  predictions[predictions < 1e-10] = 1e-10\n",
    "  return np.sum(np.multiply(labels, -np.log(predictions))) / labels.shape[0]\n",
    "\n",
    "def sample_distribution(distribution):\n",
    "  \"\"\"Sample one element from a distribution assumed to be an array of normalized\n",
    "  probabilities.\n",
    "  \"\"\"\n",
    "  r = random.uniform(0, 1)\n",
    "  s = 0\n",
    "  for i in range(len(distribution)):\n",
    "    s += distribution[i]\n",
    "    if s >= r:\n",
    "      return i\n",
    "  return len(distribution) - 1\n",
    "\n",
    "def sample(prediction):\n",
    "  \"\"\"Turn a (column) prediction into 1-hot encoded samples.\"\"\"\n",
    "  p = np.zeros(shape=[1, vocabulary_size], dtype=np.float)\n",
    "  p[0, sample_distribution(prediction[0])] = 1.0\n",
    "  return p\n",
    "\n",
    "def random_distribution():\n",
    "  \"\"\"Generate a random column of probabilities.\"\"\"\n",
    "  b = np.random.uniform(0.0, 1.0, size=[1, vocabulary_size])\n",
    "  return b/np.sum(b, 1)[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_nodes = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "  \n",
    "  # Parameters:\n",
    "  # Input gate: input, previous output, and bias.\n",
    "  ix = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ib = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Forget gate: input, previous output, and bias.\n",
    "  fx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  fb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Output gate: input, previous output, and bias.\n",
    "  ox = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  ob = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Memory cell: input, state and bias.                             \n",
    "  cx = tf.Variable(tf.truncated_normal([vocabulary_size, num_nodes], -0.1, 0.1))\n",
    "  cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], -0.1, 0.1))\n",
    "  cb = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  # Variables saving state across unrollings.\n",
    "  saved_output = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  saved_state = tf.Variable(tf.zeros([batch_size, num_nodes]), trainable=False)\n",
    "  # Classifier weights and biases.\n",
    "  w = tf.Variable(tf.truncated_normal([num_nodes, vocabulary_size], -0.1, 0.1))\n",
    "  b = tf.Variable(tf.zeros([vocabulary_size]))\n",
    "\n",
    "  # Definition of the cell computation.\n",
    "  def lstm_cell(i, o, state):\n",
    "    \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "    Note that in this formulation, we omit the various connections between the\n",
    "    previous state and the gates.\"\"\"\n",
    "    input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)\n",
    "    forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "    output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "    update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "    state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "\n",
    "    return output_gate * tf.tanh(state), state\n",
    "\n",
    "  # Input data.\n",
    "  train_inputs = tf.placeholder(tf.float32, shape=[None, vocabulary_size])\n",
    "  train_labels = tf.placeholder(tf.float32)\n",
    "\n",
    "  # Unrolled LSTM loop.\n",
    "  outputs = list()\n",
    "  output = saved_output\n",
    "  state = saved_state\n",
    "  for i in train_inputs:\n",
    "    output, state = lstm_cell(i, output, state)\n",
    "    outputs.append(output)\n",
    "\n",
    "  # State saving across unrollings.\n",
    "  with tf.control_dependencies([saved_output.assign(output),\n",
    "                                saved_state.assign(state)]):\n",
    "    # Classifier.\n",
    "    logits = tf.nn.xw_plus_b(tf.concat(outputs, 0), w, b)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "      labels=train_labels,\n",
    "      logits=logits\n",
    "    ))\n",
    "\n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0)\n",
    "  learning_rate = tf.train.exponential_decay(\n",
    "    10.0, global_step, 5000, 0.1, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "  gradients, v = zip(*optimizer.compute_gradients(loss))\n",
    "  gradients, _ = tf.clip_by_global_norm(gradients, 1.25)\n",
    "  optimizer = optimizer.apply_gradients(\n",
    "    zip(gradients, v), global_step=global_step)\n",
    "\n",
    "  # Predictions.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "  # Sampling and validation eval: batch 1, no unrolling.\n",
    "  sample_input = tf.placeholder(tf.float32, shape=[1, vocabulary_size])\n",
    "  saved_sample_output = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  saved_sample_state = tf.Variable(tf.zeros([1, num_nodes]))\n",
    "  reset_sample_state = tf.group(\n",
    "    saved_sample_output.assign(tf.zeros([1, num_nodes])),\n",
    "    saved_sample_state.assign(tf.zeros([1, num_nodes])))\n",
    "  sample_output, sample_state = lstm_cell(\n",
    "    sample_input, saved_sample_output, saved_sample_state)\n",
    "  with tf.control_dependencies([saved_sample_output.assign(sample_output),\n",
    "                                saved_sample_state.assign(sample_state)]):\n",
    "    sample_prediction = tf.nn.softmax(tf.nn.xw_plus_b(sample_output, w, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alph = \"abcdefghijklmnoprst\"\n",
    "chars = []\n",
    "\n",
    "for _ in range(10):\n",
    "  r_char = random.choice(list(alph))\n",
    "  chars.append(r_char)\n",
    "\n",
    "print(chars)\n",
    "print(chars[:3])\n",
    "print(chars[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
